{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BD-ahifbOzC"
   },
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvub3GDqbXT8"
   },
   "source": [
    "## Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E31VrWDRYlOH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split, SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchmetrics import Accuracy\n",
    "from torchinfo import summary\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import webbrowser\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "TENSORBOARD = False\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "models_path = 'models'\n",
    "plots_path = 'graphs'\n",
    "runs_path = 'runs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHpwDPdZbFzr"
   },
   "source": [
    "## Load data & initial preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aWk8jUV3YoDy",
    "outputId": "f24d8056-d0e3-4025-f5bf-e0528fc9c7d1"
   },
   "outputs": [],
   "source": [
    "# Download the FashionMNIST train and test datasets\n",
    "train_set_full = datasets.FashionMNIST(root='./datasets/', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_set = datasets.FashionMNIST(root='./datasets', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Compute the mean and std of train images\n",
    "imgs = torch.stack([img for img, _ in train_set_full], dim=0)\n",
    "mean = imgs.mean()\n",
    "std = imgs.std()\n",
    "\n",
    "# Define transformations:\n",
    "# -ToTensor: Converts images to tensors\n",
    "# -Normalise: Normalizes images to have mean 0 and std 1\n",
    "train_val_set_transforms_aug = transforms.Compose([\n",
    "    #transforms.RandomRotation(degrees=10),\n",
    "    transforms.RandomHorizontalFlip(p=0.25),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    #transforms.RandomGrayscale(p=0.2),\n",
    "    #transforms.RandomResizedCrop(size=(28, 28), scale=(0.8, 1.0)),\n",
    "    #transforms.RandomInvert(p=0.8),\n",
    "    transforms.RandomAutocontrast(p=0.2),\n",
    "    transforms.RandomSolarize(p=0.2, threshold=15),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.RandomErasing(p=0.2, scale=(0.02, 0.1), ratio=(0.1, 3.3), value=0),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "test_set_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# Apply transforms to the train and test datasets\n",
    "train_val_dataset = datasets.FashionMNIST(root='./datasets/', train=True, download=True, transform=train_val_set_transforms_aug)\n",
    "test_dataset = datasets.FashionMNIST(root='./datasets/', train=False, download=True, transform=test_set_transforms)\n",
    "\n",
    "\n",
    "# Split the train set into training and validation sets\n",
    "train_size = int(0.8 * len(train_val_dataset))\n",
    "validation_size = len(train_val_dataset) - train_size\n",
    "train_set, validation_set = random_split(train_val_dataset, [train_size, validation_size])\n",
    "\n",
    "# Create iterators for our datasets using DataLoader\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(validation_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_validation_loader = DataLoader(train_val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Select device for training. Selects GPU or MPS if available, otherwise uses CPU\n",
    "device = (\n",
    "    'cuda'\n",
    "    if torch.cuda.is_available()\n",
    "    else 'mps'\n",
    "    if torch.backends.mps.is_available()\n",
    "    else 'cpu'\n",
    ")\n",
    "print(f'Using {device} device')\n",
    "\n",
    "# Index dataset's labels to image descriptors\n",
    "labels_map = {\n",
    "    0: 'T-Shirt',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle Boot',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If tensorboard and there is a 'runs' folder, delete it to start over\n",
    "if TENSORBOARD:\n",
    "    def delete_folder(folder_path):\n",
    "        # Check if the folder exists\n",
    "        if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "            # Delete the folder\n",
    "            shutil.rmtree(folder_path)\n",
    "            print(f'Folder '{folder_path}' has been deleted.')\n",
    "        else:\n",
    "            print(f'Folder '{folder_path}' does not exist.')\n",
    "\n",
    "    folder_to_delete = runs_path\n",
    "    delete_folder(folder_to_delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXqQzXGGg_oP"
   },
   "source": [
    "## LeNet baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtF9TaVW58pU"
   },
   "source": [
    "### Define the LeNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQBTPYsIYoN9"
   },
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.first_wave = nn.Sequential(\n",
    "              nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),   # 28x28 -> 32x32 -> 28x28\n",
    "              nn.ReLU(),\n",
    "              nn.MaxPool2d(kernel_size=2, stride=2),  # 28x28 -> 14x14\n",
    "        )\n",
    "\n",
    "        self.second_wave = nn.Sequential(      \n",
    "              nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),  # 14x14 -> 10x10\n",
    "              nn.ReLU(),\n",
    "              nn.MaxPool2d(kernel_size=2, stride=2),  # 10x10 -> 5x5\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=16*5*5, out_features=120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=84, out_features=10),\n",
    "        )\n",
    "        \n",
    "        # Initialize weights using Kaiming Uniform\n",
    "        self._initialize_weights()\n",
    "        \n",
    "        # Additional output layers\n",
    "        self.aux_output1 = nn.Linear(6*14*14, 10)  # After first pooling\n",
    "        self.aux_output2 = nn.Linear(16*5*5, 10)   # After second pooling\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_wave(x)\n",
    "        aux1 = self.aux_output1(x.view(x.size(0), -1))\n",
    "        \n",
    "        x = self.second_wave(x)\n",
    "        aux2 = self.aux_output2(x.view(x.size(0), -1))\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x, aux1, aux2\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def get_features(self, x):\n",
    "        # Pass through the first wave of layers\n",
    "        x = self.first_wave(x)\n",
    "        \n",
    "        # Pass through the second wave of layers\n",
    "        x = self.second_wave(x)\n",
    "        \n",
    "        # Flatten the output for the classifier\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Pass through all layers of the classifier except the last one\n",
    "        for layer in self.classifier[:-1]:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P__sKfaa6oxV",
    "outputId": "eb1d4b59-d3aa-43d6-bbd8-5fb7f319efbe"
   },
   "outputs": [],
   "source": [
    "model_lenet5 = LeNet5()\n",
    "\n",
    "summary(model=model_lenet5, input_size=(1, 1, 28, 28), col_width=20,\n",
    "                  col_names=['input_size', 'output_size', 'num_params', 'trainable'], row_settings=['var_names'], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wtsrmYlM9QR"
   },
   "source": [
    "### Train LeNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_multiclass(model, num_classes, train_loader, validation_loader=None, device='cpu', epochs=15, lr=0.001,\n",
    "                           adapt_lr=False, adapt_lr_step=5, adapt_lr_gamma=0.5, tensorboard_tracking=False):\n",
    "    '''\n",
    "    Trains a model for multiclass classification.\n",
    "\n",
    "    :param model: model\n",
    "    :param num_classes: number of classes\n",
    "    :param train_loader: training data loader\n",
    "    :param validation_loader: validation data loader, if None then no validation\n",
    "    :param device: device choice\n",
    "    :param epochs: number of epochs\n",
    "    :param lr: learning rate\n",
    "    :param adapt_lr: True to adapt learning rate, False to keep static\n",
    "    :param adapt_lr_step: number of epochs to change learning rate after if adapt_lr is True\n",
    "    :param adapt_lr_gamma: learning rate adaptation gamma if adapt_lr is True\n",
    "    :param tensorboard_tracking: tracks training with TensorBoard if True\n",
    "\n",
    "    :return: returns model at best epoch, dictionary of training and validation results up to best epoch, and learning rates for every epoch\n",
    "    '''\n",
    "    \n",
    "    # Experiment tracking setup using TensorBoard\n",
    "    if tensorboard_tracking:\n",
    "        timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "        experiment_name = 'MNIST'\n",
    "        model_name = model.__class__.__name__\n",
    "        log_dir = os.path.join('runs', timestamp, experiment_name, model_name)\n",
    "        writer = SummaryWriter(log_dir) # Initialize a TensorBoard writer for logging\n",
    "\n",
    "    # Define Loss Function\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    # Define Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=adapt_lr_step, gamma=adapt_lr_gamma)\n",
    "    # Define output accuracy function\n",
    "    accuracy = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "    \n",
    "    # Move accuracy and model to the appropriate device\n",
    "    accuracy = accuracy.to(device)\n",
    "    model_lenet5 = model.to(device)\n",
    "    \n",
    "    history_lenet5 = {'train_loss':[], 'val_loss':[], 'train_acc': [], 'val_acc': []}\n",
    "    \n",
    "    learning_rates = []\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)): # Progress bar for epochs\n",
    "        # Initialize trining loss and accuracy\n",
    "        train_loss, train_acc = 0.0, 0.0\n",
    "    \n",
    "        # Iterating over batches of training data\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # Set model to training mode\n",
    "            model_lenet5.train()\n",
    "            # Forward pass: compute predictions\n",
    "            y_pred, _, _ = model_lenet5(X)\n",
    "            #Calculate the current batch loss and accuracy and aggregate it to the total variables\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            train_loss += loss.item()\n",
    "            acc = accuracy(y_pred, y)\n",
    "            train_acc += acc\n",
    "            # Zero out gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Backpropagate the loss\n",
    "            loss.backward()\n",
    "            # Update model parameters\n",
    "            optimizer.step()\n",
    "    \n",
    "        # Average training loss and accuracy over all batches\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc /= len(train_loader)\n",
    "        # Keep history\n",
    "        history_lenet5['train_loss'].append(train_loss)\n",
    "        history_lenet5['train_acc'].append(train_acc)\n",
    "\n",
    "        val_loss, val_acc = 0.0, 0.0\n",
    "        # If running validation\n",
    "        if validation_loader is not None:\n",
    "            # Set model to evaluation mode\n",
    "            model_lenet5.eval()\n",
    "            with torch.inference_mode(): # Context manager for inference without gradient tracking\n",
    "                # Iterating over batches of validation data\n",
    "                for X, y in validation_loader:\n",
    "                    X, y = X.to(device), y.to(device)\n",
    "        \n",
    "                    y_pred, _, _ = model_lenet5(X)\n",
    "        \n",
    "                    loss = loss_fn(y_pred, y)\n",
    "                    val_loss += loss.item()\n",
    "        \n",
    "                    acc = accuracy(y_pred, y)\n",
    "                    val_acc += acc\n",
    "        \n",
    "                # Average validation loss and accuracy over all batches\n",
    "                val_loss /= len(validation_loader)\n",
    "                val_acc /= len(validation_loader)\n",
    "                # Keep history\n",
    "                history_lenet5['val_loss'].append(val_loss)\n",
    "                history_lenet5['val_acc'].append(val_acc)\n",
    "                \n",
    "                # Check if the validation accuracy improved\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    # Save the best model state\n",
    "                    best_epoch = epoch\n",
    "                    best_model_state = model_lenet5.state_dict()\n",
    "        else:\n",
    "            # Keep values at 0 if not running validation\n",
    "            history_lenet5['val_loss'].append(val_loss)\n",
    "            history_lenet5['val_acc'].append(val_acc)\n",
    "    \n",
    "        if tensorboard_tracking:\n",
    "            # Log training and validation loss and accuracy to TensorBoard\n",
    "            writer.add_scalars(main_tag='Loss', tag_scalar_dict={'train/loss': train_loss, 'val/loss': val_loss_}, global_step=epoch)\n",
    "            writer.add_scalars(main_tag='Accuracy', tag_scalar_dict={'train/acc': train_acc, 'val/acc': val_acc}, global_step=epoch)\n",
    "    \n",
    "        print(f'Epoch: {epoch}| Train loss: {train_loss: .5f}| Train acc: {train_acc: .5f}| Val loss: {val_loss: .5f}| Val acc: {val_acc: .5f}')\n",
    "        \n",
    "        # Decrease the learning rate\n",
    "        if adapt_lr:\n",
    "            scheduler.step()\n",
    "        learning_rates.append(scheduler.get_last_lr())\n",
    "        \n",
    "    # After training\n",
    "    if best_model_state is not None:\n",
    "        model_lenet5.load_state_dict(best_model_state)\n",
    "        # Cut the history up to the best epoch\n",
    "        history_lenet5['train_loss'] = history_lenet5['train_loss'][:best_epoch + 1]\n",
    "        history_lenet5['train_acc'] = history_lenet5['train_acc'][:best_epoch + 1]\n",
    "        history_lenet5['val_loss'] = history_lenet5['val_loss'][:best_epoch + 1]\n",
    "        history_lenet5['val_acc'] = history_lenet5['val_acc'][:best_epoch + 1]\n",
    "\n",
    "    if tensorboard_tracking:\n",
    "        writer.close()\n",
    "\n",
    "    return model_lenet5, history_lenet5, learning_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lenet5, history_lenet5, learning_rates_lenet5 = train_model_multiclass(model_lenet5, 10, train_loader, validation_loader, device,\n",
    "                                                                             EPOCHS, LEARNING_RATE,\n",
    "                                                                             tensorboard_tracking=TENSORBOARD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the descriptive layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lenet5.eval()\n",
    "with torch.no_grad():\n",
    "    # Get one batch of data\n",
    "    for images, _ in test_loader:\n",
    "        images = images.to(device)\n",
    "        _, aux1, aux2 = model_lenet5(images)\n",
    "\n",
    "        # Select the first image in the batch for visualization\n",
    "        scores_aux1 = aux1[0].cpu().numpy()\n",
    "        scores_aux2 = aux2[0].cpu().numpy()\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title('Aux1 Output for the First Image')\n",
    "        plt.bar(np.arange(10), scores_aux1)\n",
    "        plt.xlabel('Classes')\n",
    "        plt.ylabel('Scores')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title('Aux2 Output for the First Image')\n",
    "        plt.bar(np.arange(10), scores_aux2)\n",
    "        plt.xlabel('Classes')\n",
    "        plt.ylabel('Scores')\n",
    "\n",
    "        plt.show()\n",
    "        break  # Only visualize for the first batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test in how many images the first Conv layer predicted the same as the second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "matching_highest_scores = 0\n",
    "\n",
    "model_lenet5.eval()\n",
    "with torch.no_grad():\n",
    "    for X, y in train_loader:\n",
    "        X = X.to(device)\n",
    "        _, aux1, aux2 = model_lenet5(X)\n",
    "\n",
    "        # Get the indices of the max score for each sample in the batch\n",
    "        max_indices_aux1 = torch.argmax(aux1, dim=1)\n",
    "        max_indices_aux2 = torch.argmax(aux2, dim=1)\n",
    "\n",
    "        # Count how many times the highest scoring classes match\n",
    "        matches = torch.sum(max_indices_aux1 == max_indices_aux2)\n",
    "        matching_highest_scores += matches.item()\n",
    "\n",
    "        total_samples += X.size(0)\n",
    "\n",
    "# Calculate the percentage\n",
    "percentage_matching = (matching_highest_scores / total_samples) * 100\n",
    "print(f'Percentage of matching highest scores: {percentage_matching:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels_list = []\n",
    "\n",
    "model_lenet5.eval()\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        X = X.to(device)\n",
    "        feature = model_lenet5.get_features(X)\n",
    "        features.append(feature.cpu().numpy())\n",
    "        labels_list.append(y.numpy())\n",
    "\n",
    "features = np.concatenate(features, axis=0)\n",
    "labels = np.concatenate(labels_list, axis=0)\n",
    "\n",
    "features = features[::1]\n",
    "labels = labels[::1]\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=123).fit_transform(features)\n",
    "\n",
    "# Create a color map with distinct colors for each label\n",
    "custom_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',\n",
    "                 '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "custom_cmap = ListedColormap(custom_colors)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(tsne[:, 0], tsne[:, 1], c=labels, cmap=custom_cmap)\n",
    "plt.title('t-SNE visualization of LeNet5 penultimate layer features')\n",
    "\n",
    "# Calculate centroids for each class\n",
    "centroids = {}\n",
    "for i in range(10):\n",
    "    indices = labels == i\n",
    "    centroids[i] = np.mean(tsne[indices], axis=0)\n",
    "    \n",
    "# Plot label names at centroids\n",
    "for i, centroid in centroids.items():\n",
    "    plt.text(centroid[0], centroid[1], labels_map[i],\n",
    "             color='black', fontsize=12, fontweight='demi', ha='center', va='center')   \n",
    "    \n",
    "\n",
    "# Create a legend\n",
    "handles = [mpatches.Patch(color=custom_cmap(i), label=labels_map[i]) for i in range(10)]\n",
    "plt.legend(handles=handles, title='Clothing Items', fontsize='6', loc='lower left')\n",
    "\n",
    "# Save plot to file\n",
    "save_path = os.path.join(plots_path +'/', f'tSNE.png')\n",
    "plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot metrics and store model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OjeP8c08a0g8"
   },
   "outputs": [],
   "source": [
    "def plot_train_val_metrics(history, model_name, plots_path='graphs'):\n",
    "    '''\n",
    "    Plots accuracy and loss for training and validation sets and outputs to file.\n",
    "\n",
    "    :param history: dictionary of training and validation results\n",
    "    :param model_name: model name for plot title and output file name\n",
    "    :param plots_path: plots directory path\n",
    "    '''\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Training Loss', color='black')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss', color='red')\n",
    "    plt.title('Training & Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Training Accuracy', color='black')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy', color='red')\n",
    "    plt.title('Training & Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Add a main title for the whole figure\n",
    "    plt.suptitle(f'Training and Validation Metrics for {model_name}', fontsize=16, y=1.05)\n",
    "\n",
    "    # Adjust layout and show plot\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot to file\n",
    "    save_path = os.path.join(plots_path +'/', f'{model_name}_metrics.png')\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model(model, model_name, models_path='models'):\n",
    "    '''\n",
    "    Outputs model to file.\n",
    "\n",
    "    :param model: model\n",
    "    :param model_name: model name for output file name\n",
    "    :param models_path: models directory path\n",
    "    '''\n",
    "\n",
    "    # Export model to TorchScript\n",
    "    model_scripted = torch.jit.script(model)\n",
    "    \n",
    "    # Save model\n",
    "    save_path = os.path.join(models_path, model_name + '.pt')\n",
    "    model_scripted.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "xajP8MBtenUx",
    "outputId": "de1d8b39-7d64-48a3-ff03-d5b63b8f2d78"
   },
   "outputs": [],
   "source": [
    "plot_train_val_metrics(history_lenet5, 'lenet5', plots_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model(model_lenet5, 'lenet5_model_original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrUwXtmRgvpv"
   },
   "source": [
    "### Evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    '''\n",
    "    Tests a trained model on test data.\n",
    "\n",
    "    :param model: model\n",
    "    :param test_loader: test data loader\n",
    "    :return: returns test loss, test accuracy, predicted labels, and actual labels\n",
    "    '''\n",
    "    \n",
    "    # model to the appropriate device\n",
    "    model_lenet5 = model.to(device)\n",
    "    \n",
    "    test_loss, test_acc = 0, 0\n",
    "    y_preds = []\n",
    "    y_labels = []\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model_lenet5.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Iterating over batches of test data\n",
    "        for X, y in test_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred, _, _ = model_lenet5(X)\n",
    "    \n",
    "            test_loss += loss_fn(y_pred, y)\n",
    "            test_acc += accuracy(y_pred, y)\n",
    "    \n",
    "            # Store predictions and labels for confusion matrix\n",
    "            y_preds.extend(y_pred.argmax(dim=1).cpu().numpy())\n",
    "            y_labels.extend(y.cpu().numpy())\n",
    "\n",
    "        # Average test loss and accuracy over all batches\n",
    "        test_loss /= len(test_loader)\n",
    "        test_acc /= len(test_loader)\n",
    "    \n",
    "    print(f'Test loss: {test_loss: .5f}| Test acc: {test_acc: .5f}')\n",
    "\n",
    "    return test_loss, test_acc, y_preds, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0Y6n-jPMXqP",
    "outputId": "0df66930-9335-4c51-bd5c-2ffff5ac407c"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc, y_preds, y_labels = test_model(model_lenet5, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See random images with their labels\n",
    "torch.manual_seed(22)  # setting random seed\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "\n",
    "rows, cols = 6, 10\n",
    "for i in range(1, (rows * cols) + 1):\n",
    "    random_idx = torch.randint(0, len(test_dataset), size=[1]).item()\n",
    "    img, label_gt = test_dataset[random_idx]\n",
    "    img_temp = img.unsqueeze(dim=0).to(device)\n",
    "    # print(img.shape)\n",
    "    label_pred = int(torch.argmax(model_lenet5(img_temp)[0]))\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    img = img.permute(1, 2, 0)    # CWH --> WHC\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    if label_pred == label_gt:\n",
    "        plt.title(labels_map[label_pred], color='g') # green label for correct prediction\n",
    "    else:\n",
    "        plt.title(labels_map[label_pred], color='r') # red label for incorrect prediction\n",
    "    plt.axis(False)\n",
    "    plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6msQF60VeHL"
   },
   "source": [
    "## Model variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfRSGq2AVk49"
   },
   "source": [
    "### 1st variant\n",
    "Change learning rate to adaptive learning rate (1/2 every 5 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHgGlI6-pM1b"
   },
   "outputs": [],
   "source": [
    "class LeNet5_v1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.first_wave = nn.Sequential(\n",
    "              nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),   # 28x28 -> 32x32 -> 28x28\n",
    "              nn.ReLU(),\n",
    "              nn.MaxPool2d(kernel_size=2, stride=2),  # 28x28 -> 14x14\n",
    "        )\n",
    "\n",
    "        self.second_wave = nn.Sequential(      \n",
    "              nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),  # 14x14 -> 10x10\n",
    "              nn.ReLU(),\n",
    "              nn.MaxPool2d(kernel_size=2, stride=2),  # 10x10 -> 5x5\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=16*5*5, out_features=120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=84, out_features=10),\n",
    "        )\n",
    "        \n",
    "        # Initialize weights using Kaiming Uniform\n",
    "        self._initialize_weights()\n",
    "        \n",
    "        # Additional output layers\n",
    "        self.aux_output1 = nn.Linear(6*14*14, 10)  # After first pooling\n",
    "        self.aux_output2 = nn.Linear(16*5*5, 10)   # After second pooling\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_wave(x)\n",
    "        aux1 = self.aux_output1(x.view(x.size(0), -1))\n",
    "        \n",
    "        x = self.second_wave(x)\n",
    "        aux2 = self.aux_output2(x.view(x.size(0), -1))\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x, aux1, aux2\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def get_features(self, x):\n",
    "        # Pass through the first wave of layers\n",
    "        x = self.first_wave(x)\n",
    "        \n",
    "        # Pass through the second wave of layers\n",
    "        x = self.second_wave(x)\n",
    "        \n",
    "        # Flatten the output for the classifier\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Pass through all layers of the classifier except the last one\n",
    "        for layer in self.classifier[:-1]:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mLmw6lN-Ugmn"
   },
   "outputs": [],
   "source": [
    "model_lenet5_v1 = LeNet5_v1()\n",
    "\n",
    "summary(model=model_lenet5_v1, input_size=(1, 1, 28, 28), col_width=20,\n",
    "                  col_names=['input_size', 'output_size', 'num_params', 'trainable'], row_settings=['var_names'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lenet5_v1, history_lenet5_v1, learning_rates_lenet5_v1 = train_model_multiclass(model_lenet5_v1, 10, train_loader, validation_loader, device,\n",
    "                                                                                      EPOCHS, LEARNING_RATE, True, 5, 0.5,\n",
    "                                                                                      tensorboard_tracking=TENSORBOARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qi4uA1NKZLiZ"
   },
   "outputs": [],
   "source": [
    "plot_train_val_metrics(history_lenet5_v1, 'lenet5_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model(model_lenet5_v1, 'lenet5_model_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr(lr_per_epoch, file_name='adaptive_lr', plots_path='graphs'):\n",
    "    '''\n",
    "    Plots learning rates for every epoch and outputs to file.\n",
    "\n",
    "    :param lr_per_epoch: learning rate for every epoch\n",
    "    :param file_name: output file name (exclusing extension)\n",
    "    :param plots_path: plots directory path\n",
    "    '''\n",
    "    # Plot learning rate\n",
    "    plt.plot(lr_per_epoch)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.title('Adaptive Learning Rate During Training')\n",
    "\n",
    "    # Save plot to file\n",
    "    save_path = os.path.join(plots_path +'/', file_name + '.png')\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lr(learning_rates_lenet5_v1, 'adaptive_lr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4Tx0E8NXQjS"
   },
   "source": [
    "### 2nd variant\n",
    "Increase number of filters in convolution layers from 6 and 16 to 32 and 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-QHZxD4qUghw"
   },
   "outputs": [],
   "source": [
    "class LeNet5_v2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.first_wave = nn.Sequential(\n",
    "              nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2),   # 28x28 -> 32x32 -> 28x28\n",
    "              nn.ReLU(),\n",
    "              nn.MaxPool2d(kernel_size=2, stride=2),  # 28x28 -> 14x14\n",
    "        )\n",
    "\n",
    "        self.second_wave = nn.Sequential(      \n",
    "              nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1),  # 14x14 -> 10x10\n",
    "              nn.ReLU(),\n",
    "              nn.MaxPool2d(kernel_size=2, stride=2),  # 10x10 -> 5x5\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=64*5*5, out_features=120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=84, out_features=10),\n",
    "        )\n",
    "        \n",
    "        # Initialize weights using Kaiming Uniform\n",
    "        self._initialize_weights()\n",
    "        \n",
    "        # Additional output layers\n",
    "        self.aux_output1 = nn.Linear(32*14*14, 10)  # After first pooling\n",
    "        self.aux_output2 = nn.Linear(64*5*5, 10)   # After second pooling\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_wave(x)\n",
    "        aux1 = self.aux_output1(x.view(x.size(0), -1))\n",
    "        \n",
    "        x = self.second_wave(x)\n",
    "        aux2 = self.aux_output2(x.view(x.size(0), -1))\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x, aux1, aux2\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def get_features(self, x):\n",
    "        # Pass through the first wave of layers\n",
    "        x = self.first_wave(x)\n",
    "        \n",
    "        # Pass through the second wave of layers\n",
    "        x = self.second_wave(x)\n",
    "        \n",
    "        # Flatten the output for the classifier\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Pass through all layers of the classifier except the last one\n",
    "        for layer in self.classifier[:-1]:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37mgX56PUge_"
   },
   "outputs": [],
   "source": [
    "model_lenet5_v2 = LeNet5_v2()\n",
    "\n",
    "summary(model=model_lenet5_v2, input_size=(1, 1, 28, 28), col_width=20,\n",
    "                  col_names=['input_size', 'output_size', 'num_params', 'trainable'], row_settings=['var_names'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lenet5_v2, history_lenet5_v2, learning_rates_lenet5_v2 = train_model_multiclass(model_lenet5_v2, 10, train_loader, validation_loader, device,\n",
    "                                                                                      EPOCHS, LEARNING_RATE, True, 5, 0.5,\n",
    "                                                                                      tensorboard_tracking=TENSORBOARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SR3LwLtxgSj6"
   },
   "outputs": [],
   "source": [
    "plot_train_val_metrics(history_lenet5_v2, 'lenet5_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model(model_lenet5_v2, 'lenet5_model_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3N2YUedXn14"
   },
   "source": [
    "### 3rd variant\n",
    "Increase neurons in fully connected layers from 120 and 84 to 200 and 140 (maintain 0.7 ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqILmpBHXm3G"
   },
   "outputs": [],
   "source": [
    "class LeNet5_v3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.first_wave = nn.Sequential(\n",
    "              nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2),   # 28x28 -> 32x32 -> 28x28\n",
    "              nn.ReLU(),\n",
    "              nn.MaxPool2d(kernel_size=2, stride=2),  # 28x28 -> 14x14\n",
    "        )\n",
    "\n",
    "        self.second_wave = nn.Sequential(      \n",
    "              nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1),  # 14x14 -> 10x10\n",
    "              nn.ReLU(),\n",
    "              nn.MaxPool2d(kernel_size=2, stride=2),  # 10x10 -> 5x5\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=64*5*5, out_features=200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=200, out_features=140),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=140, out_features=10),\n",
    "        )\n",
    "        \n",
    "        # Initialize weights using Kaiming Uniform\n",
    "        self._initialize_weights()\n",
    "        \n",
    "        # Additional output layers\n",
    "        self.aux_output1 = nn.Linear(32*14*14, 10)  # After first pooling\n",
    "        self.aux_output2 = nn.Linear(64*5*5, 10)   # After second pooling\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_wave(x)\n",
    "        aux1 = self.aux_output1(x.view(x.size(0), -1))\n",
    "        \n",
    "        x = self.second_wave(x)\n",
    "        aux2 = self.aux_output2(x.view(x.size(0), -1))\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x, aux1, aux2\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def get_features(self, x):\n",
    "        # Pass through the first wave of layers\n",
    "        x = self.first_wave(x)\n",
    "        \n",
    "        # Pass through the second wave of layers\n",
    "        x = self.second_wave(x)\n",
    "        \n",
    "        # Flatten the output for the classifier\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Pass through all layers of the classifier except the last one\n",
    "        for layer in self.classifier[:-1]:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Be1iXE2kXm1K"
   },
   "outputs": [],
   "source": [
    "model_lenet5_v3 = LeNet5_v3()\n",
    "\n",
    "summary(model=model_lenet5_v3, input_size=(1, 1, 28, 28), col_width=20,\n",
    "                  col_names=['input_size', 'output_size', 'num_params', 'trainable'], row_settings=['var_names'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lenet5_v3, history_lenet5_v3, learning_rates_lenet5_v3 = train_model_multiclass(model_lenet5_v3, 10, train_loader, validation_loader, device,\n",
    "                                                                                      EPOCHS, LEARNING_RATE, True, 5, 0.5,\n",
    "                                                                                      tensorboard_tracking=TENSORBOARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VlIueJrWgdV-"
   },
   "outputs": [],
   "source": [
    "plot_train_val_metrics(history_lenet5_v3, 'lenet5_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model(model_lenet5_v3, 'lenet5_model_v3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgLelv8dYUyD"
   },
   "source": [
    "### 4th variant\n",
    "Add batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCw7-arFXmj6"
   },
   "outputs": [],
   "source": [
    "class LeNet5_v4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.first_wave = nn.Sequential(\n",
    "              nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2),   # 28x28 -> 32x32 -> 28x28\n",
    "              nn.BatchNorm2d(32),\n",
    "              nn.ReLU(),\n",
    "              nn.MaxPool2d(kernel_size=2, stride=2),  # 28x28 -> 14x14\n",
    "        )\n",
    "\n",
    "        self.second_wave = nn.Sequential(      \n",
    "              nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1),  # 14x14 -> 10x10\n",
    "              nn.BatchNorm2d(64),\n",
    "              nn.ReLU(),\n",
    "              nn.MaxPool2d(kernel_size=2, stride=2),  # 10x10 -> 5x5\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=64*5*5, out_features=200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=200, out_features=140),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=140, out_features=10),\n",
    "        )\n",
    "        \n",
    "        # Initialize weights using Kaiming Uniform\n",
    "        self._initialize_weights()\n",
    "        \n",
    "        # Additional output layers\n",
    "        self.aux_output1 = nn.Linear(32*14*14, 10)  # After first pooling\n",
    "        self.aux_output2 = nn.Linear(64*5*5, 10)   # After second pooling\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_wave(x)\n",
    "        aux1 = self.aux_output1(x.view(x.size(0), -1))\n",
    "        \n",
    "        x = self.second_wave(x)\n",
    "        aux2 = self.aux_output2(x.view(x.size(0), -1))\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x, aux1, aux2\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def get_features(self, x):\n",
    "        # Pass through the first wave of layers\n",
    "        x = self.first_wave(x)\n",
    "        \n",
    "        # Pass through the second wave of layers\n",
    "        x = self.second_wave(x)\n",
    "        \n",
    "        # Flatten the output for the classifier\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Pass through all layers of the classifier except the last one\n",
    "        for layer in self.classifier[:-1]:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xMdSxt6Xmhe"
   },
   "outputs": [],
   "source": [
    "model_lenet5_v4 = LeNet5_v4()\n",
    "\n",
    "summary(model=model_lenet5_v4, input_size=(1, 1, 28, 28), col_width=20,\n",
    "                  col_names=['input_size', 'output_size', 'num_params', 'trainable'], row_settings=['var_names'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lenet5_v4, history_lenet5_v4, learning_rates_lenet5_v4 = train_model_multiclass(model_lenet5_v4, 10, train_loader, validation_loader, device,\n",
    "                                                                                      EPOCHS, LEARNING_RATE, True, 5, 0.5,\n",
    "                                                                                      tensorboard_tracking=TENSORBOARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Z8AH7gQZiYg"
   },
   "outputs": [],
   "source": [
    "plot_train_val_metrics(history_lenet5_v4, 'lenet5_v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GhRGOtxWZiUB"
   },
   "outputs": [],
   "source": [
    "export_model(model_lenet5_v4, 'lenet5_model_v4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store results in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model_metrics(model_metrics, file_name='model_metrics'):\n",
    "    '''\n",
    "    Outputs best epoch model training and validation results to file.\n",
    "\n",
    "    :param model_metrics: dictionary of best epoch training and validation results dictionaries for every model\n",
    "    :param file_name: output file name (exclusing extension)\n",
    "    '''\n",
    "    file_name = file_name + '.csv'\n",
    "    with open(file_name, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write the header\n",
    "        header = ['Model', 'Train Loss', 'Validation Loss', 'Train Accuracy', 'Validation Accuracy']\n",
    "        writer.writerow(header)\n",
    "\n",
    "        # Write the data for each model\n",
    "        for model_name, metrics in model_metrics.items():\n",
    "            row = [\n",
    "                model_name,\n",
    "                metrics['train_loss'],\n",
    "                metrics['val_loss'],\n",
    "                metrics['train_acc'].item() if torch.is_tensor(metrics['train_acc']) else metrics['train_acc'],\n",
    "                metrics['val_acc'].item() if torch.is_tensor(metrics['val_acc']) else metrics['val_acc']\n",
    "            ]\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {\n",
    "    'lenet5_model_original': {'train_loss': history_lenet5['train_loss'][-1], \n",
    "                              'val_loss': history_lenet5['val_loss'][-1], \n",
    "                              'train_acc': history_lenet5['train_acc'][-1], \n",
    "                              'val_acc': history_lenet5['val_acc'][-1]},\n",
    "    'lenet5_model_v1': {'train_loss': history_lenet5_v1['train_loss'][-1], \n",
    "                        'val_loss': history_lenet5_v1['val_loss'][-1], \n",
    "                        'train_acc': history_lenet5_v1['train_acc'][-1], \n",
    "                        'val_acc': history_lenet5_v1['val_acc'][-1]},\n",
    "    'lenet5_model_v2': {'train_loss': history_lenet5_v2['train_loss'][-1], \n",
    "                        'val_loss': history_lenet5_v2['val_loss'][-1], \n",
    "                        'train_acc': history_lenet5_v2['train_acc'][-1], \n",
    "                        'val_acc': history_lenet5_v2['val_acc'][-1]},\n",
    "    'lenet5_model_v3': {'train_loss': history_lenet5_v3['train_loss'][-1], \n",
    "                        'val_loss': history_lenet5_v3['val_loss'][-1], \n",
    "                        'train_acc': history_lenet5_v3['train_acc'][-1], \n",
    "                        'val_acc': history_lenet5_v3['val_acc'][-1]},\n",
    "    'lenet5_model_v4': {'train_loss': history_lenet5_v4['train_loss'][-1], \n",
    "                        'val_loss': history_lenet5_v4['val_loss'][-1], \n",
    "                        'train_acc': history_lenet5_v4['train_acc'][-1], \n",
    "                        'val_acc': history_lenet5_v4['val_acc'][-1]},\n",
    "}\n",
    "\n",
    "export_model_metrics(model_metrics, 'final_model_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model with the highest validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('final_model_metrics.csv')\n",
    "\n",
    "# Find the id of the model with the max Validation Accuracy\n",
    "max_val_acc_id = results['Validation Accuracy'].idxmax()\n",
    "\n",
    "# Retrieve the row of this specific model\n",
    "max_model = results.loc[max_val_acc_id]\n",
    "\n",
    "max_val_acc_formatted = float('{:.3f}'.format(max_model['Validation Accuracy'])) *100\n",
    "\n",
    "print(f'The model with the highest validation accuracy ({max_val_acc_formatted}%) is {max_model['Model']}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model_file = f'models/{max_model['Model']}.pt'\n",
    "model = torch.jit.load(model_file)\n",
    "\n",
    "test_loss, test_acc, y_preds, y_labels = test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(preds, labels, labels_map, file_name='confusion_matrix', plots_path='graphs'):\n",
    "    '''\n",
    "    Plots confusion matrix of predicted labels and actual labels and outputs to file.\n",
    "\n",
    "    :param preds: predicted labels\n",
    "    :param labels: actual labels\n",
    "    :param labels_map: dictionary indexing dataset's labels to image descriptors\n",
    "    :param file_name: output file name (exclusing extension)\n",
    "    :param plots_path: plots directory path\n",
    "    '''\n",
    "    \n",
    "    # Extract label names in the order of their numerical values\n",
    "    label_names = [labels_map[i] for i in range(len(labels_map))]\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_names, yticklabels=label_names)\n",
    "    plt.xlabel('True labels')\n",
    "    plt.ylabel('Predicted labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    \n",
    "    # Save plot to file\n",
    "    save_path = os.path.join(plots_path +'/', file_name + '.png')\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_preds, y_labels, labels_map, 'cm_best_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model with the highest validation accuracy after retraining on train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize appropriate model\n",
    "if max_model['Model'] == lenet5_model_original:\n",
    "    model = LeNet5()\n",
    "    adapt_lr = False\n",
    "elif max_model['Model'] == 'lenet_model_v1':\n",
    "    model = LeNet5_v1()\n",
    "    adapt_lr = True\n",
    "elif max_model['Model'] == 'lenet_model_v2':\n",
    "    model = LeNet5_v2()\n",
    "    adapt_lr = True\n",
    "elif max_model['Model'] == 'lenet_model_v3':\n",
    "    model = LeNet5_v3()\n",
    "    adapt_lr = True\n",
    "elif max_model['Model'] == 'lenet_model_v4':\n",
    "    model = LeNet5_v4()\n",
    "    adapt_lr = True\n",
    "\n",
    "# Retrain model on both train and validation data\n",
    "model, history, learning_rates = train_model_multiclass(model, 10, train_validation_loader, None, device,\n",
    "                                                        EPOCHS, LEARNING_RATE, adapt_lr, 5, 0.5,\n",
    "                                                        tensorboard_tracking=TENSORBOARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc, y_preds, y_labels = test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_preds, y_labels, labels_map, 'cm_best_model_retrained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3N2YUedXn14"
   },
   "source": [
    "### Retrain the model with the highest validation accuracy with k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results for for k-fold cross validation\n",
    "kf_results = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "\n",
    "# Initialize the k-fold cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Loop through each fold\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(train_val_dataset)):\n",
    "    # Create data loaders for training and validation sets for fold\n",
    "    train_loader_fold = torch.utils.data.DataLoader(train_val_dataset, batch_size=BATCH_SIZE, sampler=SubsetRandomSampler(train_idx))\n",
    "    validation_loader_fold = torch.utils.data.DataLoader(train_val_dataset, batch_size=BATCH_SIZE, sampler=SubsetRandomSampler(test_idx))\n",
    "\n",
    "    # Initialize appropriate model\n",
    "    if max_model['Model'] == lenet5_model_original:\n",
    "        model_fold = LeNet5()\n",
    "        adapt_lr = False\n",
    "    elif max_model['Model'] == 'lenet_model_v1':\n",
    "        model_fold = LeNet5_v1()\n",
    "        adapt_lr = True\n",
    "    elif max_model['Model'] == 'lenet_model_v2':\n",
    "        model_fold = LeNet5_v2()\n",
    "        adapt_lr = True\n",
    "    elif max_model['Model'] == 'lenet_model_v3':\n",
    "        model_fold = LeNet5_v3()\n",
    "        adapt_lr = True\n",
    "    elif max_model['Model'] == 'lenet_model_v4':\n",
    "        model_fold = LeNet5_v4()\n",
    "        adapt_lr = True\n",
    "\n",
    "    # Train model on fold\n",
    "    model_fold, history_fold, learning_rates_fold = train_model_multiclass(model_fold, 10, train_loader_fold, validation_loader_fold, device,\n",
    "                                                                           EPOCHS, LEARNING_RATE, adapt_lr, 5, 0.5,\n",
    "                                                                           tensorboard_tracking=TENSORBOARD)\n",
    "\n",
    "    # Export model for fold\n",
    "    export_model(model_fold, max_model['Model'] + '_crossval_fold' + str(fold + 1))\n",
    "    \n",
    "    # Plot results for fold\n",
    "    plot_train_val_metrics(history_fold, 'lenet5_crossval_fold' + str(fold + 1))\n",
    "\n",
    "    # Store performance metrics for fold\n",
    "    kf_results['train_loss'].append(history_fold['train_loss'][-1])\n",
    "    kf_results['train_acc'].append(history_fold['train_acc'][-1])\n",
    "    kf_results['val_loss'].append(history_fold['val_loss'][-1])\n",
    "    kf_results['val_acc'].append(history_fold['val_acc'][-1])\n",
    "\n",
    "# Calculate averages across folds\n",
    "avg_train_loss = np.mean(kf_results['train_loss'])\n",
    "avg_train_acc = np.mean(kf_results['train_acc'])\n",
    "avg_val_loss = np.mean(kf_results['val_loss'])\n",
    "avg_val_acc = np.mean(kf_results['val_acc'])\n",
    "\n",
    "print('Average Training Loss:', avg_train_loss)\n",
    "print('Average Training Accuracy:', avg_train_acc)\n",
    "print('Average Validation Loss:', avg_val_loss)\n",
    "print('Average Validation Accuracy:', avg_val_acc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0eaa97e736a846f6bdce5ffcfa4f72ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24355416b99c4f8181840659bd46f691": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5930e5fc31d249fe82ab170b190e0a2e",
      "placeholder": "​",
      "style": "IPY_MODEL_57c9cc959ab143149b5a39c986150cad",
      "value": "100%"
     }
    },
    "2e745357dcdb4e0b98212a0c344eee52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_24355416b99c4f8181840659bd46f691",
       "IPY_MODEL_45af558a35824123b177289d04050ff3",
       "IPY_MODEL_b789786a6f5c4a07ad9577a1788aaf2e"
      ],
      "layout": "IPY_MODEL_78c66e652733412ba9513bb01236be0f"
     }
    },
    "45af558a35824123b177289d04050ff3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d42d58b288e4b3491142947aa50ebf3",
      "max": 12,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_80bd1b176c4c4762867251ff84703de4",
      "value": 12
     }
    },
    "4d42d58b288e4b3491142947aa50ebf3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57c9cc959ab143149b5a39c986150cad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5930e5fc31d249fe82ab170b190e0a2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78c66e652733412ba9513bb01236be0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80bd1b176c4c4762867251ff84703de4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "92d0e6d70bf64ba28d989466ce201ca4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b789786a6f5c4a07ad9577a1788aaf2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0eaa97e736a846f6bdce5ffcfa4f72ad",
      "placeholder": "​",
      "style": "IPY_MODEL_92d0e6d70bf64ba28d989466ce201ca4",
      "value": " 12/12 [04:41&lt;00:00, 23.45s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
